# Stable-Diffusion
Stable Diffusion  åšå®¢ä»‹ç»ï¼šhttps://huggingface.co/blog/stable_diffusion

stable-diffusion-webui-colabï¼š https://github.com/camenduru/stable-diffusion-webui-colab


è¿è¡Œåœ°å€ï¼š
https://colab.research.google.com/drive/1Gg_dUYWet87CSKZ3vpZqYN97nX7DQ1hH#scrollTo=DCancU56vEwm

loraæ¨¡å‹ï¼š
```
from diffusers import StableDiffusionPipeline, DEISMultistepScheduler
 
model_id = "./model/cilloutmixNi"
 
pipe = StableDiffusionPipeline.from_pretrained(model_id, custom_pipeline="lpw_stable_diffusion")
pipe.scheduler = DEISMultistepScheduler.from_config(pipe.scheduler.config)
pipe = pipe.to("cuda")
 
prompt = "<lora:koreanDollLikeness_v10:0.8>, best quality, ultra high res, (photorealistic:1.4), 1woman, sleeveless white button shirt, black skirt, black choker, cute, (Kpop idol), (aegyo sal:1), (silver hair:1), ((puffy eyes)), looking at viewer, peace sign"
negative_prompt = "paintings, sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, age spot, glans, nsfw, nipples"
 
image = pipe(
    prompt,
    num_inference_steps=40,
    guidance_scale=10,
    width=512,
    height=512,
    max_embeddings_multiples=2,
    negative_prompt=negative_prompt
).images[0]
 
image.save("test.png")
```


ç¨³å®šæ‰©æ•£æ˜¯ç”±[CompVis](https://github.com/CompVis)ï¼Œ[Stability AI](https://stability.ai/)å’Œ[LAION](https://laion.ai/)çš„ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆåˆ›å»ºçš„æ–‡æœ¬åˆ°å›¾åƒæ½œåœ¨æ‰©æ•£æ¨¡å‹ã€‚ å®ƒæ˜¯åœ¨[æ¥è‡ªLAION-512B](https://laion.ai/blog/laion-5b/)æ•°æ®åº“å­é›†çš„512x5å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚*LAION-5B*æ˜¯ç›®å‰å­˜åœ¨çš„æœ€å¤§ï¼Œå¯è‡ªç”±è®¿é—®çš„å¤šæ¨¡æ€æ•°æ®é›†ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬æƒ³å±•ç¤ºå¦‚ä½•å°†ç¨³å®šæ‰©æ•£ä¸[æ‰©æ•£å™¨åº“ä¸€èµ·ä½¿ç”¨ğŸ§¨](https://github.com/huggingface/diffusers)ï¼Œè§£é‡Šæ¨¡å‹æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œæœ€åæ›´æ·±å…¥åœ°æ¢è®¨å¦‚ä½•å…è®¸ ä¸€ä¸ªç”¨äºè‡ªå®šä¹‰æ˜ åƒç”Ÿæˆç®¡é“ã€‚`diffusers`

**æ³¨æ„**ï¼šå¼ºçƒˆå»ºè®®å¯¹æ‰©æ•£æ¨¡å‹çš„å·¥ä½œåŸç†æœ‰ä¸€ä¸ªåŸºæœ¬çš„äº†è§£ã€‚å¦‚æœæ‰©æ•£ æ¨¡å‹å¯¹æ‚¨æ¥è¯´æ˜¯å…¨æ–°çš„ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨é˜…è¯»ä»¥ä¸‹åšå®¢æ–‡ç« ä¹‹ä¸€ï¼š

*   [å¸¦æ³¨é‡Šçš„æ‰©æ•£æ¨¡å‹](https://huggingface.co/blog/annotated-diffusion)
*   [æ‰©æ•£å™¨å…¥é—¨ ğŸ§¨](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb)

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹ ç”Ÿæˆä¸€äº›å›¾åƒ ğŸ¨ .

## [](https://huggingface.co/blog/stable_diffusion#running-stable-diffusion)è¿è¡Œç¨³å®šæ‰©æ•£

### [](https://huggingface.co/blog/stable_diffusion#license)è®¸å¯è¯

åœ¨ä½¿ç”¨æ¨¡å‹ä¹‹å‰ï¼Œæ‚¨éœ€è¦æ¥å—æ¨¡å‹[è®¸å¯è¯](https://huggingface.co/spaces/CompVis/stable-diffusion-license)æ‰èƒ½ä¸‹è½½å’Œä½¿ç”¨æƒé‡ã€‚**æ³¨æ„ï¼šä¸å†éœ€è¦é€šè¿‡ UI æ˜¾å¼æ¥å—è®¸å¯è¯**ã€‚

è¯¥è®¸å¯è¯æ—¨åœ¨å‡è½»å¦‚æ­¤å¼ºå¤§çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„æ½œåœ¨æœ‰å®³å½±å“ã€‚ æˆ‘ä»¬è¦æ±‚ç”¨æˆ·**å®Œæ•´è€Œä»”ç»†åœ°é˜…è¯»è®¸å¯è¯**ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æä¾›ä¸€ä¸ªæ‘˜è¦ï¼š

1.  æ‚¨ä¸èƒ½ä½¿ç”¨è¯¥æ¨¡å‹æ•…æ„ç”Ÿæˆæˆ–å…±äº«éæ³•æˆ–æœ‰å®³çš„è¾“å‡ºæˆ–å†…å®¹ï¼Œ
2.  æˆ‘ä»¬å¯¹æ‚¨ç”Ÿæˆçš„è¾“å‡ºä¸ä¸»å¼ ä»»ä½•æƒåˆ©ï¼Œæ‚¨å¯ä»¥è‡ªç”±ä½¿ç”¨å®ƒä»¬ï¼Œå¹¶å¯¹å®ƒä»¬çš„ä½¿ç”¨è´Ÿè´£ï¼Œè¿™ä¸åº”è¿åè®¸å¯è¯ä¸­çš„è§„å®šï¼Œå¹¶ä¸”
3.  æ‚¨å¯ä»¥é‡æ–°åˆ†é…æƒé‡ï¼Œå¹¶å°†æ¨¡å‹ç”¨äºå•†ä¸šå’Œ/æˆ–æœåŠ¡ã€‚å¦‚æœæ‚¨è¿™æ ·åšï¼Œè¯·æ³¨æ„æ‚¨å¿…é¡»åŒ…å«ä¸è®¸å¯è¯ä¸­ç›¸åŒçš„ä½¿ç”¨é™åˆ¶ï¼Œå¹¶å°†CreativeML OpenRAIL-Mçš„å‰¯æœ¬å…±äº«ç»™æ‚¨çš„æ‰€æœ‰ç”¨æˆ·ã€‚

### [](https://huggingface.co/blog/stable_diffusion#usage)ç”¨æ³•

é¦–å…ˆï¼Œæ‚¨åº”è¯¥å®‰è£…ä»¥è¿è¡Œä»¥ä¸‹ä»£ç ç‰‡æ®µï¼š`diffusers==0.10.2`

```
pip install diffusers==0.10.2 transformers scipy ftfy accelerate

```

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ¨¡å‹ç‰ˆæœ¬Â [`v1-4`](https://huggingface.co/CompVis/stable-diffusion-v1-4)ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨æ¨¡å‹çš„å…¶ä»–ç‰ˆæœ¬ï¼Œä¾‹å¦‚ 1.5ã€2 å’Œ 2.1ï¼Œåªéœ€æœ€å°‘çš„ä»£ç æ›´æ”¹ã€‚

ç¨³å®šæ‰©æ•£æ¨¡å‹å¯ä»¥ä½¿ç”¨[`ç¨³å®šæ‰©æ•£ç®¡é“`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py)ä»…ç”¨å‡ è¡Œè¿›è¡Œæ¨ç†ã€‚ç®¡é“è®¾ç½®äº†ä»æ–‡æœ¬ç”Ÿæˆå›¾åƒæ‰€éœ€çš„ä¸€åˆ‡ ä¸€ä¸ªç®€å•çš„å‡½æ•°è°ƒç”¨ã€‚`from_pretrained`

```
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4")

```

å¦‚æœæœ‰å¯ç”¨çš„ GPUï¼Œè®©æˆ‘ä»¬å°†å…¶ç§»åŠ¨åˆ°ä¸€ä¸ªï¼

```
pipe.to("cuda")

```

**æ³¨æ„**ï¼šå¦‚æœæ‚¨å—åˆ° GPU å†…å­˜çš„é™åˆ¶å¹¶ä¸”å¯ç”¨çš„ GPU å†…å­˜å°‘äº 10GBï¼Œè¯· ç¡®ä¿åŠ è½½ In Float16 ç²¾åº¦è€Œä¸æ˜¯é»˜è®¤å€¼ æµ®ç‚¹æ•°32ç²¾åº¦å¦‚ä¸Šæ‰€è¿°ã€‚`StableDiffusionPipeline`

æ‚¨å¯ä»¥é€šè¿‡ä»åˆ†æ”¯åŠ è½½æƒé‡å¹¶å‘Šè¯‰æœŸæœ› è¦ä¿æŒæµ®ç‚¹16ç²¾åº¦çš„é‡é‡ï¼š`fp16``diffusers`

```
import torch
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", revision="fp16", torch_dtype=torch.float16)

```

è¦è¿è¡Œç®¡é“ï¼Œåªéœ€å®šä¹‰æç¤ºå¹¶è°ƒç”¨ ã€‚`pipe`

```
prompt = "a photograph of an astronaut riding a horse"

image = pipe(prompt).images[0]

# you can save the image with
# image.save(f"astronaut_rides_horse.png")

```





å‰é¢çš„ä»£ç æ¯æ¬¡è¿è¡Œæ—¶éƒ½ä¼šç»™ä½ ä¸€ä¸ªä¸åŒçš„å›¾åƒã€‚

å¦‚æœåœ¨æŸä¸ªæ—¶å€™å¾—åˆ°é»‘è‰²å›¾åƒï¼Œå¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹å†…éƒ¨æ„å»ºçš„å†…å®¹è¿‡æ»¤å™¨å¯èƒ½æ£€æµ‹åˆ° NSFW ç»“æœã€‚ å¦‚æœæ‚¨è®¤ä¸ºæƒ…å†µå¹¶éå¦‚æ­¤ï¼Œè¯·å°è¯•è°ƒæ•´æç¤ºæˆ–ä½¿ç”¨å…¶ä»–ç§å­ã€‚äº‹å®ä¸Šï¼Œæ¨¡å‹é¢„æµ‹åŒ…æ‹¬æœ‰å…³æ˜¯å¦é’ˆå¯¹ç‰¹å®šç»“æœæ£€æµ‹åˆ°NSFWçš„ä¿¡æ¯ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å®ƒä»¬æ˜¯ä»€ä¹ˆæ ·å­çš„ï¼š

```
result = pipe(prompt)
print(result)

```

```
{
    'images': [<PIL.Image.Image image mode=RGB size=512x512>],
    'nsfw_content_detected': [False]
}

```

å¦‚æœä½ æƒ³è¦ç¡®å®šæ€§è¾“å‡ºï¼Œä½ å¯ä»¥è®¾å®šä¸€ä¸ªéšæœºç§å­ï¼Œå¹¶å°†ä¸€ä¸ªç”Ÿæˆå™¨ä¼ é€’ç»™ç®¡é“ã€‚ æ¯æ¬¡ä½¿ç”¨å…·æœ‰ç›¸åŒç§å­çš„ç”Ÿæˆå™¨æ—¶ï¼Œæ‚¨éƒ½ä¼šè·å¾—ç›¸åŒçš„å›¾åƒè¾“å‡ºã€‚

```
import torch

generator = torch.Generator("cuda").manual_seed(1024)
image = pipe(prompt, guidance_scale=7.5, generator=generator).images[0]

# you can save the image with
# image.save(f"astronaut_rides_horse.png")

```




æ‚¨å¯ä»¥ä½¿ç”¨å‚æ•°æ›´æ”¹æ¨ç†æ­¥éª¤æ•°ã€‚`num_inference_steps`

é€šå¸¸ï¼Œä½¿ç”¨çš„æ­¥éª¤è¶Šå¤šï¼Œç»“æœè¶Šå¥½ï¼Œä½†æ˜¯æ­¥éª¤è¶Šå¤šï¼Œç”Ÿæˆæ‰€éœ€çš„æ—¶é—´å°±è¶Šé•¿ã€‚ ç¨³å®šæ‰©æ•£åœ¨ç›¸å¯¹è¾ƒå°‘çš„æ­¥éª¤ä¸‹æ•ˆæœå¾ˆå¥½ï¼Œå› æ­¤æˆ‘ä»¬å»ºè®®ä½¿ç”¨é»˜è®¤çš„æ¨ç†æ­¥éª¤æ•°ã€‚ å¦‚æœæ‚¨æƒ³è¦æ›´å¿«çš„ç»“æœï¼Œå¯ä»¥ä½¿ç”¨è¾ƒå°çš„æ•°å­—ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´é«˜è´¨é‡çš„ç»“æœï¼Œ æ‚¨å¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ•°å­—ã€‚`50`

è®©æˆ‘ä»¬å°è¯•ä½¿ç”¨è¾ƒå°‘çš„é™å™ªæ­¥éª¤è¿è¡Œç®¡é“ã€‚

```
import torch

generator = torch.Generator("cuda").manual_seed(1024)
image = pipe(prompt, guidance_scale=7.5, num_inference_steps=15, generator=generator).images[0]

# you can save the image with
# image.save(f"astronaut_rides_horse.png")

```


æ³¨æ„ç»“æ„æ˜¯ç›¸åŒçš„ï¼Œä½†å®‡èˆªå‘˜çš„æœå’Œé©¬çš„ä¸€èˆ¬å½¢å¼å­˜åœ¨é—®é¢˜ã€‚ è¿™è¡¨æ˜ä»…ä½¿ç”¨15ä¸ªå»å™ªæ­¥éª¤ä¼šæ˜¾è‘—é™ä½ç”Ÿæˆç»“æœçš„è´¨é‡ã€‚å¦‚å‰æ‰€è¿°ï¼Œå»å™ªæ­¥éª¤é€šå¸¸è¶³ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚`50`

é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨ä½¿ç”¨å¦ä¸€ä¸ªå‡½æ•°å‚æ•°ï¼Œåœ¨æ‰€æœ‰ å‰é¢çš„ä¾‹å­ã€‚ æ˜¯ä¸€ç§æé«˜å¯¹æŒ‡å¯¼ç”Ÿæˆçš„æ¡ä»¶ä¿¡å·ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºæ–‡æœ¬ï¼‰ä»¥åŠæ•´ä½“æ ·æœ¬è´¨é‡çš„ä¾ä»æ€§çš„æ–¹æ³•ã€‚ å®ƒä¹Ÿè¢«ç§°ä¸º[æ— åˆ†ç±»å™¨å¼•å¯¼](https://arxiv.org/abs/2207.12598)ï¼Œç®€å•æ¥è¯´ï¼Œå®ƒè¿«ä½¿ç”Ÿæˆæ›´å¥½åœ°åŒ¹é…æç¤ºï¼Œè¿™å¯èƒ½ä¼šä»¥ç‰ºç‰²å›¾åƒè´¨é‡æˆ–å¤šæ ·æ€§ä¸ºä»£ä»·ã€‚ ä»‹äº å’Œ ä¹‹é—´çš„å€¼é€šå¸¸æ˜¯ç¨³å®šæ‰©æ•£çš„ä¸é”™é€‰æ‹©ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œç®¡é“ ä½¿ç”¨ 7.5 çš„ aã€‚`num_inference_steps``guidance_scale``guidance_scale``7``8.5``guidance_scale`

å¦‚æœä½¿ç”¨éå¸¸å¤§çš„å€¼ï¼Œå›¾åƒå¯èƒ½çœ‹èµ·æ¥ä¸é”™ï¼Œä½†ä¼šä¸é‚£ä¹ˆå¤šæ ·åŒ–ã€‚ æ‚¨å¯ä»¥åœ¨å¸–å­çš„[è¿™ä¸€éƒ¨åˆ†ä¸­](https://huggingface.co/blog/stable_diffusion#how-to-write-your-own-inference-pipeline-with-diffusers)äº†è§£æ­¤å‚æ•°çš„æŠ€æœ¯ç»†èŠ‚ã€‚

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä¸€æ¬¡ç”ŸæˆåŒä¸€æç¤ºçš„å¤šä¸ªå›¾åƒã€‚ é¦–å…ˆï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥å¸®åŠ©æˆ‘ä»¬åœ¨ç½‘æ ¼ä¸­å¾ˆå¥½åœ°å¯è§†åŒ–å®ƒä»¬ã€‚`image_grid`

```
from PIL import Image

def image_grid(imgs, rows, cols):
    assert len(imgs) == rows*cols

    w, h = imgs[0].size
    grid = Image.new('RGB', size=(cols*w, rows*h))
    grid_w, grid_h = grid.size

    for i, img in enumerate(imgs):
        grid.paste(img, box=(i%cols*w, i//cols*h))
    return grid

```

æˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•åœ°ä½¿ç”¨é‡å¤å¤šæ¬¡ç›¸åŒæç¤ºçš„åˆ—è¡¨æ¥ä¸ºåŒä¸€æç¤ºç”Ÿæˆå¤šä¸ªå›¾åƒã€‚æˆ‘ä»¬å°†åˆ—è¡¨å‘é€åˆ°ç®¡é“ï¼Œè€Œä¸æ˜¯æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨çš„å­—ç¬¦ä¸²ã€‚

```
num_images = 3
prompt = ["a photograph of an astronaut riding a horse"] * num_images

images = pipe(prompt).images

grid = image_grid(images, rows=1, cols=3)

# you can save the grid with
# grid.save(f"astronaut_rides_horse.png")

```



é»˜è®¤æƒ…å†µä¸‹ï¼Œç¨³å®šæ‰©æ•£ä¼šäº§ç”Ÿåƒç´ å›¾åƒã€‚ä½¿ç”¨ and å‚æ•°è¦†ç›–é»˜è®¤å€¼éå¸¸å®¹æ˜“ï¼Œä»¥çºµå‘æˆ–æ¨ªå‘æ¯”ä¾‹åˆ›å»ºçŸ©å½¢å›¾åƒã€‚`512 Ã— 512``height``width`

é€‰æ‹©å›¾åƒå°ºå¯¸æ—¶ï¼Œæˆ‘ä»¬å»ºè®®å¦‚ä¸‹ï¼š

*   ç¡®ä¿ å’Œ éƒ½æ˜¯ çš„å€æ•°ã€‚`height``width``8`
*   ä½äº 512 å¯èƒ½ä¼šå¯¼è‡´å›¾åƒè´¨é‡è¾ƒä½ã€‚
*   åœ¨ä¸¤ä¸ªæ–¹å‘ä¸Šè¶…è¿‡ 512 å°†é‡å¤å›¾åƒåŒºåŸŸï¼ˆå…¨å±€ä¸€è‡´æ€§ä¸¢å¤±ï¼‰ã€‚
*   åˆ›å»ºéæ–¹å½¢å›¾åƒçš„æœ€ä½³æ–¹æ³•æ˜¯åœ¨ä¸€ä¸ªç»´åº¦ä¸­ä½¿ç”¨ï¼Œå¹¶åœ¨å¦ä¸€ä¸ªç»´åº¦ä¸­ä½¿ç”¨å¤§äºè¯¥å€¼çš„å€¼ã€‚`512`

è®©æˆ‘ä»¬è¿è¡Œä¸€ä¸ªç¤ºä¾‹ï¼š

```
prompt = "a photograph of an astronaut riding a horse"
image = pipe(prompt, height=512, width=768).images[0]

# you can save the image with
# image.save(f"astronaut_rides_horse.png")

```

## [](https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work)ç¨³å®šæ‰©æ•£å¦‚ä½•å·¥ä½œï¼Ÿ

çœ‹è¿‡ç¨³å®šæ‰©æ•£å¯ä»¥äº§ç”Ÿçš„é«˜è´¨é‡å›¾åƒåï¼Œè®©æˆ‘ä»¬è¯•ç€äº†è§£ä¸€ä¸‹ æ¨¡å‹çš„åŠŸèƒ½æ›´å¥½ä¸€äº›ã€‚

ç¨³å®šæ‰©æ•£åŸºäºä¸€ç§ç§°ä¸ºæ½œåœ¨æ‰©æ•£çš„ç‰¹å®šç±»å‹çš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨å…·æœ‰[æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„é«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆ](https://arxiv.org/abs/2112.10752)ä¸­æå‡ºã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œæ‰©æ•£æ¨¡å‹æ˜¯æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼Œç»è¿‡è®­ç»ƒå¯ä»¥é€æ­¥*å»å™ª*éšæœºé«˜æ–¯å™ªå£°ï¼Œä»¥è·å¾—æ„Ÿå…´è¶£çš„æ ·æœ¬ï¼Œä¾‹å¦‚*å›¾åƒ*ã€‚æœ‰å…³å®ƒä»¬å¦‚ä½•å·¥ä½œçš„æ›´è¯¦ç»†æ¦‚è¿°ï¼Œè¯·æŸ¥çœ‹[æ­¤ colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb)ã€‚

æ‰©æ•£æ¨¡å‹å·²ç»è¯æ˜å¯ä»¥å®ç°ç”Ÿæˆå›¾åƒæ•°æ®çš„æœ€æ–°ç»“æœã€‚ä½†æ‰©æ•£æ¨¡å‹çš„ä¸€ä¸ªç¼ºç‚¹æ˜¯ï¼Œåå‘å»å™ªè¿‡ç¨‹å¾ˆæ…¢ï¼Œå› ä¸ºå®ƒå…·æœ‰é‡å¤çš„é¡ºåºæ€§è´¨ã€‚æ­¤å¤–ï¼Œè¿™äº›æ¨¡å‹æ¶ˆè€—å¤§é‡å†…å­˜ï¼Œå› ä¸ºå®ƒä»¬åœ¨åƒç´ ç©ºé—´ä¸­è¿è¡Œï¼Œåœ¨ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒæ—¶ä¼šå˜å¾—å¾ˆå¤§ã€‚å› æ­¤ï¼Œè®­ç»ƒè¿™äº›æ¨¡å‹å¹¶å°†å…¶ç”¨äºæ¨ç†å…·æœ‰æŒ‘æˆ˜æ€§ã€‚

æ½œåœ¨æ‰©æ•£å¯ä»¥é€šè¿‡åœ¨è¾ƒä½ç»´åº¦*çš„æ½œåœ¨*ç©ºé—´ä¸Šåº”ç”¨æ‰©æ•£è¿‡ç¨‹æ¥é™ä½å†…å­˜å’Œè®¡ç®—å¤æ‚æ€§ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å®é™…åƒç´ ç©ºé—´ã€‚è¿™æ˜¯æ ‡å‡†æ‰©æ•£å’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ä¹‹é—´çš„ä¸»è¦åŒºåˆ«ï¼š**åœ¨æ½œåœ¨æ‰©æ•£ä¸­ï¼Œæ¨¡å‹è¢«è®­ç»ƒä»¥ç”Ÿæˆå›¾åƒçš„æ½œåœ¨ï¼ˆå‹ç¼©ï¼‰è¡¨ç¤ºã€‚**

æ½œä¼æ‰©æ•£æœ‰ä¸‰ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ã€‚

1.  è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰ã€‚
2.  [ä¸€ä¸ªU-Net](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb#scrollTo=wW8o1Wp0zRkq)ã€‚
3.  æ–‡æœ¬ç¼–ç å™¨ï¼Œ*ä¾‹å¦‚*Â [CLIP çš„æ–‡æœ¬ç¼–ç å™¨](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)ã€‚

**1\. è‡ªåŠ¨ç¼–ç å™¨ ï¼ˆVAEï¼‰**

VAEå‹å·ç”±ç¼–ç å™¨å’Œè§£ç å™¨ä¸¤éƒ¨åˆ†ç»„æˆã€‚ç¼–ç å™¨ç”¨äºå°†å›¾åƒè½¬æ¢ä¸ºä½ç»´æ½œåœ¨è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºå°†ç”¨ä½œ*U-Net*æ¨¡å‹çš„è¾“å…¥ã€‚ ç›¸åï¼Œè§£ç å™¨å°†æ½œåœ¨è¡¨ç¤ºè½¬æ¢å›å›¾åƒã€‚

åœ¨æ½œåœ¨æ‰©æ•£*è®­ç»ƒ*æœŸé—´ï¼Œç¼–ç å™¨ç”¨äºè·å–å‰å‘æ‰©æ•£è¿‡ç¨‹å›¾åƒçš„æ½œåœ¨è¡¨ç¤ºï¼ˆ*æ½œåœ¨*è¡¨ç¤ºï¼‰ï¼Œåœ¨æ¯ä¸€æ­¥åº”ç”¨è¶Šæ¥è¶Šå¤šçš„å™ªå£°ã€‚åœ¨*æ¨ç†*è¿‡ç¨‹ä¸­ï¼Œåå‘æ‰©æ•£è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å»å™ªæ½œä¼é€šè¿‡VAEè§£ç å™¨è½¬æ¢å›å›¾åƒã€‚æ­£å¦‚æˆ‘ä»¬å°†åœ¨æ¨ç†è¿‡ç¨‹ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬**åªéœ€è¦VAEè§£ç å™¨**ã€‚

**2\. U-Net**

U-Netæœ‰ä¸€ä¸ªç¼–ç å™¨éƒ¨åˆ†å’Œä¸€ä¸ªè§£ç å™¨éƒ¨åˆ†ï¼Œéƒ½ç”±ResNetå—ç»„æˆã€‚ ç¼–ç å™¨å°†å›¾åƒè¡¨ç¤ºå‹ç¼©ä¸ºè¾ƒä½åˆ†è¾¨ç‡çš„å›¾åƒè¡¨ç¤ºï¼Œè§£ç å™¨å°†è¾ƒä½åˆ†è¾¨ç‡çš„å›¾åƒè¡¨ç¤ºè§£ç å›åŸå§‹çš„é«˜åˆ†è¾¨ç‡å›¾åƒè¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºçš„å™ªå£°è¾ƒå°ã€‚ æ›´å…·ä½“åœ°è¯´ï¼ŒU-Netè¾“å‡ºé¢„æµ‹å™ªå£°æ®‹å·®ï¼Œå¯ç”¨äºè®¡ç®—é¢„æµ‹çš„å»å™ªå›¾åƒè¡¨ç¤ºã€‚

ä¸ºäº†é˜²æ­¢U-Netåœ¨ä¸‹é‡‡æ ·æ—¶ä¸¢å¤±é‡è¦ä¿¡æ¯ï¼Œé€šå¸¸åœ¨ç¼–ç å™¨çš„ä¸‹é‡‡æ ·ResNetå’Œè§£ç å™¨çš„ä¸Šé‡‡æ ·ResNetä¹‹é—´æ·»åŠ å¿«æ·æ–¹å¼è¿æ¥ã€‚ æ­¤å¤–ï¼Œç¨³å®šçš„æ‰©æ•£U-Netèƒ½å¤Ÿé€šè¿‡äº¤å‰æ³¨æ„åŠ›å±‚å°†å…¶è¾“å‡ºæ¡ä»¶åŒ–ä¸ºæ–‡æœ¬åµŒå…¥ã€‚äº¤å‰æ³¨æ„å±‚é€šå¸¸æ·»åŠ åˆ°U-Netçš„ç¼–ç å™¨å’Œè§£ç å™¨éƒ¨åˆ†ï¼Œé€šå¸¸åœ¨ResNetå—ä¹‹é—´ã€‚

**3\. æ–‡æœ¬ç¼–ç å™¨**

æ–‡æœ¬ç¼–ç å™¨è´Ÿè´£å°†è¾“å…¥æç¤ºï¼ˆ*ä¾‹å¦‚*â€œå®‡èˆªå‘˜éª‘é©¬â€ï¼‰è½¬æ¢ä¸ºU-Netå¯ä»¥ç†è§£çš„åµŒå…¥ç©ºé—´ã€‚å®ƒé€šå¸¸æ˜¯*ä¸€ä¸ªç®€å•çš„åŸºäºè½¬æ¢å™¨çš„*ç¼–ç å™¨ï¼Œå®ƒå°†ä¸€ç³»åˆ—è¾“å…¥æ ‡è®°æ˜ å°„åˆ°ä¸€ç³»åˆ—æ½œåœ¨çš„æ–‡æœ¬åµŒå…¥ã€‚

å—Â [Imagen](https://imagen.research.google/)Â çš„å¯å‘ï¼Œç¨³å®š**æ‰©æ•£ä¸ä¼šåœ¨**è®­ç»ƒæœŸé—´è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨ï¼Œè€Œåªæ˜¯ä½¿ç”¨ CLIP å·²ç»è®­ç»ƒçš„æ–‡æœ¬ç¼–ç å™¨Â [CLIPTextModel](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)ã€‚

**ä¸ºä»€ä¹ˆæ½œåœ¨æ‰©æ•£å¿«é€Ÿé«˜æ•ˆï¼Ÿ**

ç”±äºæ½œåœ¨æ‰©æ•£åœ¨ä½ç»´ç©ºé—´ä¸Šè¿è¡Œï¼Œå› æ­¤ä¸åƒç´ ç©ºé—´æ‰©æ•£æ¨¡å‹ç›¸æ¯”ï¼Œå®ƒå¤§å¤§é™ä½äº†å†…å­˜å’Œè®¡ç®—è¦æ±‚ã€‚ä¾‹å¦‚ï¼Œç¨³å®šæ‰©æ•£ä¸­ä½¿ç”¨çš„è‡ªåŠ¨ç¼–ç å™¨çš„æŠ˜å‡ç³»æ•°ä¸º 8ã€‚è¿™æ„å‘³ç€å½¢çŠ¶çš„å›¾åƒå˜ä¸ºæ½œåœ¨ç©ºé—´ï¼Œè¿™éœ€è¦çš„å†…å­˜è¦å°‘å‡ å€ã€‚`(3, 512, 512)``(3, 64, 64)``8 Ã— 8 = 64`

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå³ä½¿åœ¨ 16GB Colab GPU ä¸Šä¹Ÿèƒ½å¦‚æ­¤å¿«é€Ÿåœ°ç”Ÿæˆå›¾åƒçš„åŸå› ï¼`512 Ã— 512`

**æ¨ç†è¿‡ç¨‹ä¸­çš„ç¨³å®šæ‰©æ•£**

ç»¼ä¸Šæ‰€è¿°ï¼Œç°åœ¨è®©æˆ‘ä»¬é€šè¿‡è¯´æ˜é€»è¾‘æµæ¥ä»”ç»†çœ‹çœ‹æ¨¡å‹åœ¨æ¨ç†ä¸­çš„å·¥ä½œåŸç†ã€‚

[å›¾ç‰‡ä¸Šä¼ ä¸­...(image-8a4c8a-1678157858353-6)]

ç¨³å®šæ‰©æ•£æ¨¡å‹å°†æ½œåœ¨ç§å­å’Œæ–‡æœ¬æç¤ºä½œä¸ºè¾“å…¥ã€‚ç„¶åä½¿ç”¨æ½œåœ¨ç§å­ç”Ÿæˆå¤§å°çš„éšæœºæ½œåœ¨å›¾åƒè¡¨ç¤º<math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn _msttexthash="10322" _msthash="96">64</mn><mo _msttexthash="19565" _msthash="97">Ã—</mo><mn _msttexthash="10322" _msthash="98">64</mn></mrow></semantics></math>64Ã—64å…¶ä¸­ï¼Œæ–‡æœ¬æç¤ºè½¬æ¢ä¸ºå¤§å°çš„æ–‡æœ¬åµŒå…¥<math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn _msttexthash="10725" _msthash="103">77</mn><mo _msttexthash="19565" _msthash="104">Ã—</mo><mn _msttexthash="17173" _msthash="105">768</mn></mrow></semantics></math>77Ã—768é€šè¿‡ CLIP çš„æ–‡æœ¬ç¼–ç å™¨ã€‚

æ¥ä¸‹æ¥ï¼ŒU-Netè¿­ä»£åœ°å¯¹éšæœºæ½œåœ¨å›¾åƒè¡¨ç¤ºè¿›è¡Œ*é™å™ªï¼Œ*åŒæ—¶ä»¥æ–‡æœ¬åµŒå…¥ä¸ºæ¡ä»¶ã€‚U-Netçš„è¾“å‡ºä½œä¸ºå™ªå£°æ®‹å·®ï¼Œç”¨äºé€šè¿‡è°ƒåº¦å™¨ç®—æ³•è®¡ç®—å»å™ªçš„æ½œåœ¨å›¾åƒè¡¨ç¤ºã€‚è®¸å¤šä¸åŒçš„è°ƒåº¦ç¨‹åºç®—æ³•å¯ç”¨äºæ­¤è®¡ç®—ï¼Œæ¯ç§ç®—æ³•éƒ½æœ‰å…¶ä¼˜ç‚¹å’Œç¼ºç‚¹ã€‚å¯¹äºç¨³å®šæ‰©æ•£ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ä»¥ä¸‹ä¹‹ä¸€ï¼š

*   [PNDM è°ƒåº¦ç¨‹åº](https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py)ï¼ˆé»˜è®¤ä½¿ç”¨ï¼‰
*   [DDIM è°ƒåº¦ç¨‹åº](https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py)
*   [K-LMS è°ƒåº¦ç¨‹åº](https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py)

å…³äºè°ƒåº¦ç¨‹åºç®—æ³•å‡½æ•°å¦‚ä½•è¶…å‡ºæœ¬ç¬”è®°æœ¬èŒƒå›´çš„ç†è®ºï¼Œä½†ç®€è€Œè¨€ä¹‹ï¼Œåº”è¯¥è®°ä½ï¼Œä»–ä»¬æ ¹æ®å…ˆå‰çš„å™ªå£°è¡¨ç¤ºå’Œé¢„æµ‹çš„å™ªå£°æ®‹å·®è®¡ç®—é¢„æµ‹çš„å»å™ªå›¾åƒè¡¨ç¤ºã€‚ æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œæˆ‘ä»¬å»ºè®®ç ”ç©¶é˜æ˜[åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹çš„è®¾è®¡ç©ºé—´](https://arxiv.org/abs/2206.00364)

*å»å™ª*è¿‡ç¨‹é‡å¤*çº¦*50æ¬¡ï¼Œä»¥é€æ­¥æ£€ç´¢æ›´å¥½çš„æ½œåœ¨å›¾åƒè¡¨ç¤ºã€‚ å®Œæˆåï¼Œæ½œåœ¨å›¾åƒè¡¨ç¤ºç”±å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨çš„è§£ç å™¨éƒ¨åˆ†è§£ç ã€‚

åœ¨å¯¹æ½œåœ¨å’Œç¨³å®šæ‰©æ•£çš„ç®€è¦ä»‹ç»ä¹‹åï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•é«˜çº§ä½¿ç”¨ğŸ¤—æ‹¥æŠ±è„¸åº“ï¼`diffusers`

## [](https://huggingface.co/blog/stable_diffusion#writing-your-own-inference-pipeline)ç¼–å†™è‡ªå·±çš„æ¨ç†ç®¡é“

æœ€åï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ åˆ›å»ºè‡ªå®šä¹‰æ‰©æ•£ç®¡çº¿ã€‚ ç¼–å†™è‡ªå®šä¹‰æ¨ç†ç®¡é“æ˜¯è¯¥åº“çš„é«˜çº§ç”¨æ³•ï¼Œå¯ç”¨äºåˆ‡æ¢æŸäº›ç»„ä»¶ï¼Œä¾‹å¦‚ä¸Šé¢è§£é‡Šçš„VAEæˆ–è°ƒåº¦ç¨‹åºã€‚`diffusers``diffusers`

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•å°†ç¨³å®šæ‰©æ•£ä¸ä¸åŒçš„è°ƒåº¦å™¨ä¸€èµ·ä½¿ç”¨ï¼Œå³[åœ¨æ­¤ PR](https://github.com/huggingface/diffusers/pull/185)Â ä¸­æ·»åŠ [çš„ Katherine Crowson çš„](https://github.com/crowsonkb)Â K-LMS è°ƒåº¦å™¨ã€‚

[é¢„è®­ç»ƒæ¨¡å‹](https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/main)åŒ…æ‹¬è®¾ç½®å®Œæ•´æ‰©æ•£ç®¡é“æ‰€éœ€çš„æ‰€æœ‰ç»„ä»¶ã€‚å®ƒä»¬å­˜å‚¨åœ¨ä»¥ä¸‹æ–‡ä»¶å¤¹ä¸­ï¼š

*   `text_encoder`ï¼šç¨³å®šæ‰©æ•£ä½¿ç”¨ CLIPï¼Œä½†å…¶ä»–æ‰©æ•£æ¨¡å‹å¯èƒ½ä½¿ç”¨å…¶ä»–ç¼–ç å™¨ï¼Œä¾‹å¦‚ ã€‚`BERT`
*   `tokenizer`.å®ƒå¿…é¡»ä¸æ¨¡å‹ä½¿ç”¨çš„åŒ¹é…ã€‚`text_encoder`
*   `scheduler`ï¼šç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ­¥å‘å›¾åƒæ·»åŠ å™ªå£°çš„è°ƒåº¦ç®—æ³•ã€‚
*   `unet`ï¼šç”¨äºç”Ÿæˆè¾“å…¥çš„æ½œåœ¨è¡¨ç¤ºçš„æ¨¡å‹ã€‚
*   `vae`ï¼šè‡ªåŠ¨ç¼–ç å™¨æ¨¡å—ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å®ƒå°†æ½œåœ¨è¡¨ç¤ºè§£ç ä¸ºçœŸå®å›¾åƒã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡å¼•ç”¨ç»„ä»¶ä¿å­˜çš„æ–‡ä»¶å¤¹æ¥åŠ è½½ç»„ä»¶ï¼Œä½¿ç”¨å‚æ•° .`subfolder``from_pretrained`

```
from transformers import CLIPTextModel, CLIPTokenizer
from diffusers import AutoencoderKL, UNet2DConditionModel, PNDMScheduler

# 1\. Load the autoencoder model which will be used to decode the latents into image space. 
vae = AutoencoderKL.from_pretrained("CompVis/stable-diffusion-v1-4", subfolder="vae")

# 2\. Load the tokenizer and text encoder to tokenize and encode the text. 
tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-large-patch14")
text_encoder = CLIPTextModel.from_pretrained("openai/clip-vit-large-patch14")

# 3\. The UNet model for generating the latents.
unet = UNet2DConditionModel.from_pretrained("CompVis/stable-diffusion-v1-4", subfolder="unet")

```

ç°åœ¨ï¼Œæˆ‘ä»¬ä¸å†åŠ è½½é¢„å®šä¹‰çš„è°ƒåº¦ç¨‹åºï¼Œè€Œæ˜¯ä½¿ç”¨ä¸€äº›æ‹Ÿåˆå‚æ•°åŠ è½½Â [K-LMS è°ƒåº¦å™¨](https://github.com/huggingface/diffusers/blob/71ba8aec55b52a7ba5a1ff1db1265ffdd3c65ea2/src/diffusers/schedulers/scheduling_lms_discrete.py#L26)ã€‚

```
from diffusers import LMSDiscreteScheduler

scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule="scaled_linear", num_train_timesteps=1000)

```

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å°†æ¨¡å‹ç§»åŠ¨åˆ° GPUã€‚

```
torch_device = "cuda"
vae.to(torch_device)
text_encoder.to(torch_device)
unet.to(torch_device) 

```

ç°åœ¨ï¼Œæˆ‘ä»¬å®šä¹‰å°†ç”¨äºç”Ÿæˆå›¾åƒçš„å‚æ•°ã€‚

è¯·æ³¨æ„ï¼Œå®šä¹‰ç±»ä¼¼äº[Imagenè®ºæ–‡](https://arxiv.org/pdf/2205.11487.pdf)ä¸­æ–¹ç¨‹ï¼ˆ2ï¼‰çš„æŒ‡å¯¼æƒé‡ã€‚ å¯¹åº”äºä¸æ‰§è¡Œæ— åˆ†ç±»å™¨æŒ‡å¯¼ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åƒä¹‹å‰ä¸€æ ·å°†å…¶è®¾ç½®ä¸º 7.5ã€‚`guidance_scale``w``guidance_scale == 1`

ä¸å‰é¢çš„ç¤ºä¾‹ç›¸æ¯”ï¼Œæˆ‘ä»¬è®¾ç½®ä¸º 100 ä»¥è·å¾—æ›´æ˜ç¡®çš„å›¾åƒã€‚`num_inference_steps`

```
prompt = ["a photograph of an astronaut riding a horse"]

height = 512                        # default height of Stable Diffusion
width = 512                         # default width of Stable Diffusion

num_inference_steps = 100           # Number of denoising steps

guidance_scale = 7.5                # Scale for classifier-free guidance

generator = torch.manual_seed(0)    # Seed generator to create the inital latent noise

batch_size = len(prompt)

```

é¦–å…ˆï¼Œæˆ‘ä»¬å¾—åˆ°ä¼ é€’çš„æç¤ºã€‚ è¿™äº›åµŒå…¥å°†ç”¨äºè°ƒèŠ‚ UNet æ¨¡å‹ï¼Œå¹¶å¼•å¯¼å›¾åƒç”Ÿæˆç±»ä¼¼äºè¾“å…¥æç¤ºçš„å†…å®¹ã€‚`text_embeddings`

```
text_input = tokenizer(prompt, padding="max_length", max_length=tokenizer.model_max_length, truncation=True, return_tensors="pt")

text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]

```

æˆ‘ä»¬è¿˜å°†è·å¾—æ— åˆ†ç±»å™¨æŒ‡å—çš„æ— æ¡ä»¶æ–‡æœ¬åµŒå…¥ï¼Œè¿™äº›åµŒå…¥åªæ˜¯å¡«å……æ ‡è®°ï¼ˆç©ºæ–‡æœ¬ï¼‰çš„åµŒå…¥ã€‚å®ƒä»¬éœ€è¦å…·æœ‰ä¸æ¡ä»¶ï¼ˆå’Œ`text_embeddings``batch_size``seq_length`)

```
max_length = text_input.input_ids.shape[-1]
uncond_input = tokenizer(
    [""] * batch_size, padding="max_length", max_length=max_length, return_tensors="pt"
)
uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]   

```

å¯¹äºæ— åˆ†ç±»å™¨æŒ‡å¯¼ï¼Œæˆ‘ä»¬éœ€è¦æ‰§è¡Œä¸¤æ¬¡æ­£å‘ä¼ é€’ï¼šä¸€æ¬¡ä½¿ç”¨æ¡ä»¶è¾“å…¥ ï¼ˆï¼‰ï¼Œå¦ä¸€æ¬¡ä½¿ç”¨æ— æ¡ä»¶åµŒå…¥ ï¼ˆï¼‰ã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¸¤è€…è¿æ¥æˆä¸€ä¸ªæ‰¹å¤„ç†ï¼Œä»¥é¿å…æ‰§è¡Œä¸¤æ¬¡æ­£å‘ä¼ é€’ã€‚`text_embeddings``uncond_embeddings`

```
text_embeddings = torch.cat([uncond_embeddings, text_embeddings])

```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç”Ÿæˆåˆå§‹éšæœºå™ªå£°ã€‚

```
latents = torch.randn(
    (batch_size, unet.in_channels, height // 8, width // 8),
    generator=generator,
)
latents = latents.to(torch_device)

```

å¦‚æœæˆ‘ä»¬åœ¨è¿™ä¸ªé˜¶æ®µæ£€æŸ¥ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å®ƒä»¬çš„å½¢çŠ¶æ˜¯ ï¼Œæ¯”æˆ‘ä»¬æƒ³è¦ç”Ÿæˆçš„å›¾åƒå°å¾—å¤šã€‚è¯¥æ¨¡å‹ç¨åä¼šå°†è¿™ç§æ½œåœ¨è¡¨ç¤ºï¼ˆçº¯å™ªå£°ï¼‰è½¬æ¢ä¸ºå›¾åƒã€‚`latents``torch.Size([1, 4, 64, 64])``512 Ã— 512`

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬é€‰æ‹©çš„ . è¿™å°†è®¡ç®—åœ¨å»å™ªè¿‡ç¨‹ä¸­è¦ä½¿ç”¨çš„ç¡®åˆ‡æ—¶é—´æ­¥é•¿å€¼ã€‚`num_inference_steps``sigmas`

```
scheduler.set_timesteps(num_inference_steps)

```

K-LMS è°ƒåº¦ç¨‹åºéœ€è¦å°† ä¹˜ä»¥å…¶å€¼ã€‚è®©æˆ‘ä»¬åœ¨è¿™é‡Œè¿™æ ·åšï¼š`latents``sigma`

```
latents = latents * scheduler.init_noise_sigma

```

æˆ‘ä»¬å·²å‡†å¤‡å¥½ç¼–å†™å»å™ªå¾ªç¯ã€‚

```
from tqdm.auto import tqdm

scheduler.set_timesteps(num_inference_steps)

for t in tqdm(scheduler.timesteps):
    # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.
    latent_model_input = torch.cat([latents] * 2)

    latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)

    # predict the noise residual
    with torch.no_grad():
        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample

    # perform guidance
    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)
    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)

    # compute the previous noisy sample x_t -> x_t-1
    latents = scheduler.step(noise_pred, t, latents).prev_sample

```

æˆ‘ä»¬ç°åœ¨ä½¿ç”¨ å°†ç”Ÿæˆçš„è§£ç å›å›¾åƒã€‚`vae``latents`

```
# scale and decode the image latents with vae
latents = 1 / 0.18215 * latents
with torch.no_grad():
    image = vae.decode(latents).sample

```

æœ€åï¼Œè®©æˆ‘ä»¬å°†å›¾åƒè½¬æ¢ä¸º PILï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥æ˜¾ç¤ºæˆ–ä¿å­˜å®ƒã€‚

```
image = (image / 2 + 0.5).clamp(0, 1)
image = image.detach().cpu().permute(0, 2, 3, 1).numpy()
images = (image * 255).round().astype("uint8")
pil_images = [Image.fromarray(image) for image in images]
pil_images[0]

```


æˆ‘ä»¬å·²ç»ä»ä½¿ç”¨æ‹¥æŠ±é¢æ‰©æ•£å™¨ç¨³å®šæ‰©æ•£çš„åŸºæœ¬ä½¿ç”¨åˆ°åº“çš„æ›´é«˜çº§ä½¿ç”¨ğŸ¤—ï¼Œæˆ‘ä»¬è¯•å›¾åœ¨ç°ä»£æ‰©æ•£ç³»ç»Ÿä¸­å¼•å…¥æ‰€æœ‰éƒ¨åˆ†ã€‚å¦‚æœæ‚¨å–œæ¬¢æœ¬ä¸»é¢˜å¹¶æƒ³è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ä½¿ç”¨ä»¥ä¸‹èµ„æºï¼š

*   æˆ‘ä»¬çš„[ç§‘æ‹‰å¸ƒç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb)ã€‚
*   [æ‰©æ•£å™¨å…¥é—¨](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb)ç¬”è®°æœ¬ï¼Œå…¶ä¸­æä¾›äº†æœ‰å…³æ‰©æ•£ç³»ç»Ÿçš„æ›´å¹¿æ³›æ¦‚è¿°ã€‚
*   [å¸¦æ³¨é‡Šçš„æ‰©æ•£æ¨¡å‹](https://huggingface.co/blog/annotated-diffusion)åšå®¢æ–‡ç« ã€‚
*   æˆ‘ä»¬åœ¨Â [GitHub ä¸­çš„ä»£ç ](https://github.com/huggingface/diffusers)ï¼Œå¦‚æœæ‚¨ç•™ä¸‹ â­ if å¯¹æ‚¨æœ‰ç”¨ï¼Œæˆ‘ä»¬å°†éå¸¸é«˜å…´ï¼`diffusers`
